inherit.aes = inherit.aes,
params = list(
trim = trim,
scale = scale,
...
)
)
}
#' @rdname ggplot2-ggproto
#' @format NULL
#' @usage NULL
#' @export
GeomFlatViolin <-
ggproto("GeomFlatViolin", Geom,
setup_data = function(data, params) {
data$width <- data$width %||%
params$width %||% (resolution(data$x, FALSE) * 0.9)
# ymin, ymax, xmin, and xmax define the bounding rectangle for each group
data %>%
group_by(group) %>%
mutate(ymin = min(y),
ymax = max(y),
xmin = x,
xmax = x + width / 2)
},
draw_group = function(data, panel_scales, coord) {
# Find the points for the line to go all the way around
data <- transform(data, xminv = x,
xmaxv = x + violinwidth * (xmax - x))
# Make sure it's sorted properly to draw the outline
newdata <- rbind(plyr::arrange(transform(data, x = xminv), y),
plyr::arrange(transform(data, x = xmaxv), -y))
# Close the polygon: set first and last point the same
# Needed for coord_polar and such
newdata <- rbind(newdata, newdata[1,])
ggplot2:::ggname("geom_flat_violin", GeomPolygon$draw_panel(newdata, panel_scales, coord))
},
draw_key = draw_key_polygon,
default_aes = aes(weight = 1, colour = "grey20", fill = "white", size = 0.5,
alpha = NA, linetype = "solid"),
required_aes = c("x", "y")
)
extract_bouts <- function(all_scans) {
solo_visits <- all_scans %>%
filter((Region1_total + Region2_total + Region3_total) == 1)
solo_visits$location = NA
solo_visits$sequence = 1
for(i in 1:nrow(solo_visits)) {
solo_visits$location[i] <- which(c(solo_visits$Region1_total[i], solo_visits$Region2_total[i], solo_visits$Region3_total[i]) == 1)
if (i >= 2) {
if (difftime(solo_visits$timestamp[i], solo_visits$timestamp[i-1], units = "mins") != 1) { solo_visits$sequence[i] = solo_visits$sequence[i-1] + 1
} else solo_visits$sequence[i] = solo_visits$sequence[i-1]
}
}
return(solo_visits)
}
solo_visits <- extract_bouts(all_kinkajou_scans)
library(stringr)
library(readr)
library(tidyr)
library(lubridate)
library(sf)
library(dplyr)
library(ggplot2)
library(gplots)
library(ggridges)
library(scales)
library(nlme)
library(brms)
library(corrplot)
library(units)
library(rethinking)
library(bayesplot)
library(tidybayes)
library(tidybayes.rethinking)
library(vioplot)
library(tibble)
library(ggforce)
#Load entropy calculation tools
setwd("C:\\Users\\avining\\Documents\\Sequence Analysis")
source("LOOK.R")
source("simp.R")
source("infoLines.R")
source("infoLines_inser_del.R")
source("group.R")
source("group_first.R")
source("infoLines_subMAT.R")
source("simp_subMAT.R")
source("inclusion.R")
source("incl_test.R")
source("draw_probPlot.R")
source("draw_seq.R")
source("entropy.R")
source("AutoO.R")
get_study_day_and_time <- function(Datetime_string, study_start) {
#study start must include the approximate start time of evening observations if overnight follows are to be binned into the correct study day
datetime_vector <- strsplit(Datetime_string, split = "")[[1]]
date1 <- paste(paste(datetime_vector[1:6], collapse = ""),
"20",
paste(datetime_vector[7:8], collapse = ""), sep = "") %>% as.POSIXct(format = "%d-%m-%Y", tz = "America/Panama")
time1 = paste(datetime_vector[9:10], collapse = "")
study_day = difftime(date1, study_start, units = "days") %>% floor()
return(list(study_day, time1))
}
get_kinkMinutesPerHour <- function(count_data, categories = 6) {
#default value for categories assumes count data has 6 rows per observational minute, representing 3 Regions x 2 states (hidden or visible)
minutes_per_hour = (sum(count_data)/(length(count_data)/categories)) * 60
return(minutes_per_hour)
}
get_growth_index <- function(time_series) {
removed = 0
while(time_series[1] == 0) {
time_series <- time_series[-1]
warning("initial observation removed due to value of 0")
removed = removed + 1
}
growth_index <- ((time_series-time_series[1])/time_series[1]) * 100
return(c(rep(NA, times = removed), growth_index))
}
get_decision_info <- function(transition_array, flower_data){
# input:
#transition_array: an array with regions transitioned from in one dimension, regions transitioned to in the second, and time in the third, where each cell gives the number of transitions that occured from region x to region y at time t
#flower_data: a dataframe with columns Adjusted_Count and Region. Should only contains data from a singe study night
decision_transitions <- apply(transition_array, MARGIN = 3, FUN = function(X) {X *matrix(c(0,1,1,0,                                                                                                                                                              1,0,1,0,                                                                                                                                                              1,1,0,0,
0,0,0,0),nrow = 4, ncol = 4)} ) %>%#this matrix is multiplied with a transition matrix to remove all transitions that are not from one region to a different region
array(dim = dim(transition_array))
if (sum(decision_transitions) <= 0) return(data.frame(matrix(ncol = 7, nrow = 0))) #if there are no decisions, returns a placeholder dataframe with 7 columns and 0 rows. Done to fit with the final form of the decision data.frame with columns for From, To, Minute, adj_flowers_to, Avoid, adj_flowers_avoid, and Study_night)
#extract information about each decision in array
decisions <- as.data.frame(which(decision_transitions > 0, arr.ind = TRUE)) #get array indices for all decisions
#below, duplicate any rows where the same decisions was made more than once in a minute
decisions <- data.frame(lapply(X = decisions,
FUN = rep,
times = mapply(function(data, dim1,dim2,dim3) data[dim1,dim2,dim3], dim1 = decisions$dim1, dim2=decisions$dim2, dim3=decisions$dim3, MoreArgs = list(data = decision_transitions))))
names(decisions) <- c("From", "To", "Minute")
decisions <- mutate(decisions,
relative_density_to = arrange(flower_data, Region)$Relative_Density[To], #get the relative flower density of the region moved to for each decision.
expected_rel_dens_to = arrange(flower_data, Region)$Expected_Relative_Density[To],
Avoid = mapply(FUN = function(to, from){ which(! c(1,2,3) %in% c(to, from))}, to = To, from = From), #get the region avoided by checking the regions transitioned from and the the region transitioned to against the possible regions (1,2,3; not generalizable to more regions)
)
decisions <- mutate(decisions, relative_density_avoid = arrange(flower_data, Region)$Relative_Density[Avoid],
expected_rel_dens_avoid = arrange(flower_data, Region)$Expected_Relative_Density[Avoid])
return(decisions)
}
"%||%" <- function(a, b) {
if (!is.null(a)) a else b
}
geom_flat_violin <- function(mapping = NULL, data = NULL, stat = "ydensity",
position = "dodge", trim = TRUE, scale = "area",
show.legend = NA, inherit.aes = TRUE, ...) {
layer(
data = data,
mapping = mapping,
stat = stat,
geom = GeomFlatViolin,
position = position,
show.legend = show.legend,
inherit.aes = inherit.aes,
params = list(
trim = trim,
scale = scale,
...
)
)
}
#' @rdname ggplot2-ggproto
#' @format NULL
#' @usage NULL
#' @export
GeomFlatViolin <-
ggproto("GeomFlatViolin", Geom,
setup_data = function(data, params) {
data$width <- data$width %||%
params$width %||% (resolution(data$x, FALSE) * 0.9)
# ymin, ymax, xmin, and xmax define the bounding rectangle for each group
data %>%
group_by(group) %>%
mutate(ymin = min(y),
ymax = max(y),
xmin = x,
xmax = x + width / 2)
},
draw_group = function(data, panel_scales, coord) {
# Find the points for the line to go all the way around
data <- transform(data, xminv = x,
xmaxv = x + violinwidth * (xmax - x))
# Make sure it's sorted properly to draw the outline
newdata <- rbind(plyr::arrange(transform(data, x = xminv), y),
plyr::arrange(transform(data, x = xmaxv), -y))
# Close the polygon: set first and last point the same
# Needed for coord_polar and such
newdata <- rbind(newdata, newdata[1,])
ggplot2:::ggname("geom_flat_violin", GeomPolygon$draw_panel(newdata, panel_scales, coord))
},
draw_key = draw_key_polygon,
default_aes = aes(weight = 1, colour = "grey20", fill = "white", size = 0.5,
alpha = NA, linetype = "solid"),
required_aes = c("x", "y")
)
file_names <- dir("../DATA/raw/Kinkajou_Scans_Nele", pattern = ".csv")
video_metadata_location <- "../DATA/raw/Video_metadata/video_file_timestamp_metadata_cam1.txt"
video_metadata <- readChar(con = video_metadata_location, nchars = file.info(video_metadata_location)$size)
video_metadata <- str_split(video_metadata, pattern = "Folder: ")[[1]][-1] #break all metadata into strings for each observation period (and remove preceding empty character)
video_metadata <- str_split(video_metadata, pattern =  "start = ") #find the start time of all files
start_timestamps <- sapply(video_metadata, function(X) str_split(X[2], pattern = "\r")[[1]][1]) #extract start time of first file and remove all extra data
start_timestamps <- as.POSIXct(start_timestamps, format = "%Y-%m-%d_%H-%M-%S", tz = "GMT")
start_timestamps <- with_tz(start_timestamps, "America/Panama")
all_kinkajou_scans <-  c()
Jan_22_check = FALSE #used later to parse two video files that started on the same day (one AM one PM)
for(file_name in file_names) {
scan_data <- read_csv(paste("../DATA/raw/Kinkajou_Scans_Nele/", file_name, sep = ""), skip = 1, progress = FALSE)
colnames(scan_data) <- c("timestamp", "Region1_total", "Region1_hidden", "Region2_total", "Region2_hidden", "Region3_total", "Region3_hidden", "Kinkajou_Notes", "Video_Notes", "Extraneous")
scan_data <- scan_data[complete.cases(scan_data$timestamp),] %>% select(! Extraneous)
start_date <- str_split(file_name ,pattern = "_Cam")[[1]][1] #str_split returns a list of string components. We want the first (and only) element of this list - then the first string element in this list gives the date
start_date <- as.POSIXct(paste("20", start_date, sep = ""), format = "%Y_%m_%d") #date needs all 4 digits
start_timestamp <- start_timestamps[which(date(start_timestamps) == start_date)]
#Two video files started on Jan 22nd, one AM and one PM. Because this is the ONLY date where this occurred, I implemented a quick and dirty check to parse the AM file first and the PM file second, below
if (length(start_timestamp) > 1)
if (! Jan_22_check) {
start_timestamp <- start_timestamp[1]
Jan_22_check <-  TRUE
} else start_timestamp <- start_timestamp[2]
#end Jan 22 case
scan_data$timestamp <- start_timestamp + period_to_seconds(hms(scan_data$timestamp))
scan_data$Study_night <- round(as.numeric(start_timestamp - start_timestamps[1], units = "days"), digits = 0)
all_kinkajou_scans <- rbind(all_kinkajou_scans, scan_data)
}
head(all_kinkajou_scans)
#convert empty count cells (NAs) to 0
count_data <- all_kinkajou_scans[,2:7] # columns 2 through 7 are the count data columns, we want NAs in the notes columns, but 0s in the count data
count_data[is.na(count_data)] <- 0
all_kinkajou_scans[,2:7] <- count_data
#The data as read contain the TOTAL number of kinkajous and the number of those total that are hidden. As suggested by the new names given to the columns in this data structure, we want the count of visible and hidden kinkajous, not the total. The adjustment is made below
all_kinkajou_scans <- mutate(all_kinkajou_scans, Region1_visible = Region1_total - Region1_hidden, Region2_visible = Region2_total - Region2_hidden, Region3_visible = Region3_total - Region3_hidden) %>%
select(timestamp, Region1_total, Region2_total, Region3_total, Region1_visible, Region1_hidden, Region2_visible, Region2_hidden, Region3_visible, Region3_hidden, Study_night, Kinkajou_Notes, Video_Notes)
#pivot dataframe to long format for easy usage in ggplot
all_kinkajou_scans_long <- pivot_longer(all_kinkajou_scans,
cols = Region1_visible:Region3_hidden,
names_to = c("Region", "Visibility"),
names_sep = "_",
values_to = "Count")
all_kinkajou_scans_long$Region <- sapply(all_kinkajou_scans_long$Region, switch, "Region1" = "1", "Region2" = "2", "Region3" = "3") %>% factor()
write.csv(all_kinkajou_scans_long, "../DATA/processed/all_kinkajou_scans.csv")
kinkajou_counts <- all_kinkajou_scans_long %>% group_by(Study_night) %>% summarise(Minutes_Per_Hour = get_kinkMinutesPerHour(Count)) %>% transform(Growth = get_growth_index(Minutes_Per_Hour))
kinkajou_counts_region <- all_kinkajou_scans_long %>% group_by(Study_night, Region) %>% summarise(Minutes_Per_Hour = get_kinkMinutesPerHour(Count, categories = 2)) %>% group_by(Region) %>% group_modify(~ transform(.x, Growth = get_growth_index(Minutes_Per_Hour)))
get_transitions <- function(count_data){
#input: a dataframe with columns "Region1_total", "Region2_total", "Region3_total" and (optionally) "timestamp".
#output: an array giving the number of transitions from one region (first dimension) to another (second dimension) for each minute (row) of the input data (third dimension)
transitions <- array(data = 0, dim = c(4,4,nrow(count_data)))
if("timestamp" %in% colnames(count_data)) arrange(count_data, timestamp)
count_data <- select(count_data, Region1_total, Region2_total, Region3_total)
for(i in 2:nrow(count_data)){
#to calculate the transition matrix, we treat the counts in the previous timestep as the row totals of the transition matrix
row_totals <- c(unlist(count_data[i-1,]),
max(sum(count_data[i,]) - sum(count_data[i -1,]), 0)) #create a fourth row total for kinkajous entering the tree by differencing the total kinkajou counts of the current timestep and the previous timestep, counting only positive differences.
#we then treat the counts in the current timestep as the column totals in the transition matrix
col_totals <- c(unlist(count_data[i,]),
max(sum(count_data[i-1,]) - sum(count_data[i,]), 0)) #create a fourth column total for kinkajous leaving the tree
for(j in seq_along(row_totals)){
for(k in seq_along(col_totals)){
m <- min(row_totals[j], col_totals[k]) #m is the maximum number of transitions that can contribute to both the relevant row total and column total
transitions[j,k,i] <- m
row_totals[j] <- row_totals[j] - m #subtract the number of transitions that have been added from the corresponding row total
col_totals[k] <- col_totals[k] - m #subtract the number of transitions that have been added from the corresponding column total
}
}
}
return(transitions)
}
transition_arrays <- all_kinkajou_scans %>% group_by(Study_night) %>% group_map(~get_transitions(.x))
names(transition_arrays) <- as.character(unique(all_kinkajou_scans$Study_night))
#the below calculations wrangle the data into a long form data frame that can fit a binomial model to determine how many kinkajous are likely to depart from a region at any given minute, as a function of the number of kinkajous in that region and the number of kinkajous in other regions. Its a little crude but gets the job done
stays <- lapply(transition_arrays, function(X) apply(X, 3, diag)[1:3,]) #diagonal element of each slice of transition array (representing a minute) give number of kinkajous that stayed in the region they were in on the previous minute
departures <- lapply(transition_arrays, function(X) apply(X, c(1,3), sum)[1:3,] - apply(X, 3, diag)[1:3,]) #summing the rows of transition array slices gives the total number of kinkajous. Subjecting the slice diagonal gives the number that moved to a new region
departures_df <- c()
for (i in seq_along(departures)){
temp_df <- data.frame(Minute = 1:ncol(departures[[i]]),
#get stays and departures for each region, given by the rows of the respective arrays (cols are minutes)
n_1 = departures[[i]][1,] + stays[[i]][1,],
n_2 = departures[[i]][2,] + stays[[i]][2,],
n_3 = departures[[i]][3,] + stays[[i]][3,],
departures_1 = departures[[i]][1,],
departures_2 = departures[[i]][2,],
departures_3 = departures[[i]][3,],
Study_Night = names(departures[i]))
departures_df <- rbind(departures_df, temp_df)
}
departures_long <- matrix(nrow = 0, ncol = 6)
for(i in 1:nrow(departures_df)) {
#Get data for Region 1
if (departures_df$n_1[i] > 0) departures_long <- rbind(departures_long, c(departures_df$Study_Night[i], #study Night
departures_df$Minute[i], #Minute
1, #Region
departures_df$n_1[i], #n
sum(departures_df$n_2[i], departures_df$n_3[i]), #Neighbors
departures_df$departures_1[i])) #Departures
#Get data for Region 2
if (departures_df$n_2[i] > 0) departures_long <- rbind(departures_long, c(departures_df$Study_Night[i],
departures_df$Minute[i],
2, #Region
departures_df$n_2[i], #n
sum(departures_df$n_1[i], departures_df$n_3[i]), #Neighbors
departures_df$departures_2[i]))
#Get data for Region 3
if (departures_df$n_3[i] > 0) departures_long <-  rbind(departures_long, c(departures_df$Study_Night[i],
departures_df$Minute[i],
3, #Region
departures_df$n_3[i], #n
sum(departures_df$n_1[i], departures_df$n_3[i]), #Neighbors
departures_df$departures_3[i]))
}
departures_long <- data.frame(matrix(as.numeric(departures_long), ncol = 6))
colnames(departures_long) <- c("Study_Night", "Minute", "Region", "n", "Neighbors", "Departures")
departures_long$Region <- factor(departures_long$Region)
filter(all_kinkajou_scans, Study_night == 20)[202:203,1:4] #first four columns give timestamp and total counts for each region
transition_arrays[["20"]][,,203]
nightly_transitions <- vector("list", length = length(transition_arrays))
names(nightly_transitions)  <-  names(transition_arrays)
for(i in seq_along(nightly_transitions)) {
nightly_transitions[[i]] <- apply(transition_arrays[[i]], MARGIN = c(1,2), sum)
}
heatmap(nightly_transitions[[13]], Rowv = NA, Colv = NA, xlab = "Region (to)", ylab = "Region (from)", main = "Transition Heatmap - Study Night 28")
heatmap.2(nightly_transitions[[13]], Rowv = NA, Colv = NA, xlab = "Region (to)", ylab = "Region (from)", main = "Transition Heatmap - Study Night 28", cellnote = nightly_transitions[[13]], trace = "none")
all_transitions <- Reduce("+", nightly_transitions)
heatmap.2(all_transitions, Rowv = NA, Colv = NA, xlab = "Region (to)", ylab = "Region (from)", main = "Transition Heatmap - All Nights", cellnote = all_transitions, trace = "none")
heatmap.2(log(all_transitions + 1), Rowv = NA, Colv = NA, xlab = "Region (to)", ylab = "Region (from)", main = "Transition Heatmap - All Nights", cellnote = round(log(all_transitions + 1), 2), trace = "none")
region_shapes <- st_read("../DATA/raw/Crown Region Shapes/Crown_Regions.shp") %>% st_set_crs("WGS84") #the shapefiles have already been used to sort flowers. THey are loaded here primarily for the purpose of determining region areas and thus flower densities
files = strsplit(dir("../DATA/raw/Flower_geopackages"), split = "[.]") #seperate filenames from extensions for all files in folder
files = files[sapply(files, function(X) X[2] == "gpkg")] #reduce file list only to gpkg files
geopackages <- vector("list", length = length(files))
for(i in seq_along(files)){
flower_sf <- st_read(paste("../DATA/raw/Flower_geopackages/", files[[i]][1], ".", files[[i]][2], sep = ""), quiet = TRUE)
flower_sf$Region <- strsplit(files[[i]][1], split = NULL)[[1]] %>% last() %>% as.numeric() + 1 #QGIS labelled regioning grouping outputs at 0 (last element of savefile string); add one to get region labels that match kinkajou data
flower_sf$Date <- strsplit(files[[i]][1], split = "_")[[1]][2]
geopackages[[i]] <- flower_sf
}
all_upflowers <- do.call(rbind, geopackages)
all_upflowers$Region <- factor(all_upflowers$Region)
#Drone flights are labelled by a character with date and time of scan. The date needs to be converted to a study day variable and the time put into its own column
all_upflowers <- all_upflowers %>% mutate(Study_night = sapply(Date, function(X) get_study_day_and_time(X, study_start = as.POSIXct("2019-12-14 18:00:00", tz = "America/Panama"))[[1]]),
Time = factor(sapply(Date, function(X) get_study_day_and_time(X, study_start= as.POSIXct("2019-12-14 18:00:00", tz = "America/Panama")) [[2]])))
print(head(all_upflowers))
all_upflowers <- all_upflowers %>% filter(Time == "AM" | !Study_night %in% c(23, 26, 25, 32)) %>% #remove data from images marked in notes as poor quality photos
filter(Time == "PM" | !Study_night %in% c(20,21)) #remove data from images marked in notes as poor quality photos
flower_counts <- all_upflowers %>%
mutate(Study_night = Study_night - (Time == "AM")) %>% #study night is based on date, but we want to match AM recordings to previous PM recording s, so we subtract one from all AM study night values
group_by(Study_night, Time) %>%
summarise(Count = n()) %>%
group_by(Study_night) %>% #where there were good photos for both AM and PM, we will use the mean flower count which is achieved by grouping and summariying
summarise(Count = mean(Count)) %>%
transform(Growth = get_growth_index(Count)) %>% #used to visually compare changes in flower count to changes in kinkajou residency without bias
mutate(Density = 10 * as.numeric(Count/(sum(st_area(region_shapes))))) #multiply by ten to get flowers per 10 m^2, which will bring down the variance on estimated effect sizes
flower_counts_region <- all_upflowers %>% mutate(Study_night = Study_night - (Time == "AM")) %>% #study night is based on date, but we want to match AM recordings to previous PM recordings, so we subtract one from all AM study night values
group_by(Study_night, Region, Time) %>%
summarise(Count = n()) %>%
group_by(Study_night, Region) %>%
summarise(Count = mean(Count)) %>%
group_by(Region) %>% group_modify(~ transform(.x, Growth = get_growth_index(Count))) %>%
ungroup()
flower_counts_region <- flower_counts_region %>% mutate(Density = 10 * as.numeric(Count/(st_area(region_shapes)[Region]))) #divide flower count by area of region to get flower density. COnvert to flowers/10m^2 to manage effect sizes
flower_counts_region <- flower_counts_region %>% mutate(Relative_Density = Density - flower_counts$Density[pmatch(Study_night, flower_counts$Study_night, duplicates.ok = TRUE)]) #match study_nights between regional and full tree flower count data, subtracting the full tree flower density from each regional density for each night
flower_counts_region$Expected_Relative_Density <- NA
for(i in 1:nrow(flower_counts_region)){
flower_counts_region$Expected_Relative_Density[i] <- mean(filter(flower_counts_region,
Study_night < flower_counts_region$Study_night[i] &
Region == flower_counts_region$Region[i])$Relative_Density)
}
#flower_averages are used in next code chunk to calculate adjusted values
flower_averages <- flower_counts_region %>%
group_by(Region) %>%
summarize(total_flowers = sum(Count)) %>%
mutate(proportion = total_flowers/sum(total_flowers))
combined_data <- merge(flower_counts, kinkajou_counts, by = "Study_night", all = TRUE)
combined_data_region <- merge(flower_counts_region, kinkajou_counts_region, by = c("Study_night","Region") , all = TRUE) %>%
mutate(Total_Flowers = combined_data$Count[pmatch(Study_night, combined_data$Study_night, duplicates.ok = TRUE)]) %>%
mutate(Adjusted_Count = Count - (Total_Flowers * flower_averages$proportion[Region]),
Average_Density = 10 * Total_Flowers/sum(st_area(region_shapes))) #get desnity in flowers/10m^2
decisions <- c()
for(i in seq_along(transition_arrays)){
new_decisions <- get_decision_info(transition_array = transition_arrays[[i]], flower_data = filter(combined_data_region, Study_night == names(transition_arrays[i]))) #see helper functions for get_decision_info
if(nrow(new_decisions) > 0) new_decisions$Study_night = names(transition_arrays[i])
decisions = rbind(decisions, new_decisions)
}
decisions <- mutate(decisions, relative_density_diff = relative_density_to - relative_density_avoid,
expected_density_diff = expected_rel_dens_to - expected_rel_dens_avoid)
decisions <- mutate(decisions, Success = relative_density_diff > 0,
Success_Expected = expected_density_diff > 0,
From_To = factor(mapply(paste, From, To, MoreArgs = list(sep = "_"))))
extract_bouts <- function(all_scans) {
solo_visits <- all_scans %>%
filter((Region1_total + Region2_total + Region3_total) == 1)
solo_visits$location = NA
solo_visits$sequence = 1
for(i in 1:nrow(solo_visits)) {
solo_visits$location[i] <- which(c(solo_visits$Region1_total[i], solo_visits$Region2_total[i], solo_visits$Region3_total[i]) == 1)
if (i >= 2) {
if (difftime(solo_visits$timestamp[i], solo_visits$timestamp[i-1], units = "mins") != 1) { solo_visits$sequence[i] = solo_visits$sequence[i-1] + 1
} else solo_visits$sequence[i] = solo_visits$sequence[i-1]
}
}
return(solo_visits)
}
solo_visits <- extract_bouts(all_kinkajou_scans)
#combine sequences 1 and 2, which are separated by a gap in video meant to fix clock drift
solo_visits$sequence[solo_visits$sequence == 2] <- 1
#Same for sequences 5 and 6
solo_visits$sequence[solo_visits$sequence == 6] <- 5
#Same for sequences 9 and 10
solo_visits$sequence[solo_visits$sequence == 10] <- 9
#Same for sequences 11 and 12
solo_visits$sequence[solo_visits$sequence == 12] <- 11
#Same for sequences 14 and 15
solo_visits$sequence[solo_visits$sequence == 15] <- 14
#Same for sequences 44-47
solo_visits$sequence[solo_visits$sequence == 45] <- 44
solo_visits$sequence[solo_visits$sequence == 46] <- 44
solo_visits$sequence[solo_visits$sequence == 47] <- 44
#61 and 62 are likely the same individual that went out of site
solo_visits$sequence[solo_visits$sequence == 62] <- 61
#combine sequences 72 and 73, which are separated by a gap in video meant to fix clock drift, and 74 which was seperated due to a missing minute
solo_visits$sequence[solo_visits$sequence == 73] <- 72
solo_visits$sequence[solo_visits$sequence == 74] <- 72
#Combine 78 and 79, which are only seperated by a missing minute
solo_visits$sequence[solo_visits$sequence == 79] <- 78
#combine sequences 88 and 89, which are separated by a gap in video meant to fix clock drift
solo_visits$sequence[solo_visits$sequence == 89] <- 88
#Combine 93 and 94, which are only seperated by a missing minute
solo_visits$sequence[solo_visits$sequence == 79] <- 78
load("../Results/reference_simulations1.Rdata")
reference1_solo_visits <- lapply(simulated_scans, extract_bouts)
get_entropy <- function(solo_visits) {
solo_transition_sequence <- solo_visits %>% group_by(sequence) %>% summarize(transitions = paste(rle(location)$values, collapse = ""))
solo_transition_sequence <- paste(solo_transition_sequence$transitions, collapse = "S") %>% strsplit(split = "")
return(entropy(solo_transition_sequence[[1]])) #from entropy analysis code, loaded at top of markdown
}
empirical_entropy <- get_entropy(solo_visits)
reference1_entropy <- lapply(reference1_solo_visits, get_entropy)
{plot(empirical_entropy, type = "l", lwd = 2, ylim = c(min(unlist(reference1_entropy)), max(unlist(reference1_entropy))))
for(i in seq_along(reference1_entropy)){
lines(reference1_entropy[[i]], col = alpha("red", 0.1))
}
}
library(ForageR)
library(ggplot2)
field <- st_buffer(st_point(c(10,0)), 15) %>% st_sfc()
foragers <-   createForagers(1, #number of foragers
type = "dBRW", #dBRW = distance selection Biased Random Walk. This is one way of defining randomness and correlation in agent movement. It inherets from a class that is purely random and can apply these methods too.
bounds = field,
concentrations = 0.1, #concentration variable name comes from the parameter used for a wrapped cauchy distribution, but I call the variable directedness when defining because that seems more intuitive/applicable. Will rename to add clarity
speeds = 1,
sights = 1,
giving_up_density = 0.6,
quiet = TRUE,        #prevents warnings I set up to notify users of parameters that are being set to defaults
choice_determinism = 1, #note abbreviation for iterative loops above
efficiency = 1,
persistences = 0) #abbreviation from parameter iteration loop
foragers[[1]]$setTarget
patches <- list(st_point(c(3,0)),st_point(c(0,10)),st_point(c(10,10)),st_point(c(10,-14)),st_point(c(20,10)),st_point(c(17,0))) %>%
st_sfc() %>%
st_buffer(dist = 1) %>%                                          #transform generated points into circles with given patch radius
data.frame(geom = .,
NAME = as.character(1:length(.)),
MAX_VALUE = 10,
VALUE = 9,
REGEN = 0.1,
TYPE = "Resource") %>%
st_sf()
landmarks <- rep(st_buffer(field, dist = -2), times = 20) %>%        #start by defining the bounds within which each point should be created. Here, a single boundary defines possible space for all points, hence the use of rep
sapply(ForageR::generateBoundedPoint) %>% st_sfc() %>%                               #for each boundary given, generate a spatial point within that space then store points into a spatial features collection
st_buffer(dist = 0.25) %>%                                          #transform generated points into circles with given patch radius
ForageR:::seperate_patches() %>%
data.frame(geom = .,
NAME = as.character(LETTERS[1:length(.)]),
MAX_VALUE = 0,
VALUE = 0,
REGEN = 0,
TYPE = "Landmark") %>% st_sf()
landscape <- rbind(patches, landmarks)
simulator <- Environment(foragers = foragers, bounds = field, patches = rbind(patches, landmarks))
for(step in 1:500) {
simulator$progress()
}
choices <- ForageR:::getChoices(simulator$foragers[[1]], landscape)
choices
simulator$foragers[[1]]$sight <- 60
choices <- ForageR:::getChoices(simulator$foragers[[1]], landscape)
choices
if(! is.na(choices) choices <- filter(choices, (VALUE * efficiency) > giving_up_density)
if(! is.na(choices)) choices <- filter(choices, (VALUE * efficiency) > giving_up_density)
is.na(choices)
# Function to calculate distance between a forager and a set of patches, then return the patches withing sight range of the forager and their distances
#' @title Choice Finder
#' @param forager A single object of Forager class
#' @param patches A simple features data frame with a geom column containing the geometries of patches.
#' @importFrom units set_units
getChoices <- function(forager, patches) {
recentVisits <- forager$visitSeq[c((length(forager$visitSeq) - (forager$repeatAvoid - 1)):length(forager$visitSeq))] #check which patches forager has visited recently
patches <- patches[! patches$NAME %in% recentVisits & (patches$VALUE * forager$efficiency) > forager$giving_up_density,] #remove recently visited patches and those that would be passed over according to the marginal value theorem
distances <- set_units(st_distance(forager$location, patches), NULL) #get distances to each patch
if (sum(distances <= forager$sight) == 0) return(NA)                                                                        #if no patches in sight, return no target
choices <- patches[which(distances[1,] <= forager$sight),]
choices$DIST <- distances[distances[1,] <= forager$sight]
return(choices)
}
choices = getChoices(simulator$foragers[[1]], landscape)
library(units)
choices = getChoices(simulator$foragers[[1]], landscape)
choices
build()
setwd("~/Foraging Simulator")
library(devtools)
build()
install()
